
<div class="container-fluid">
	<div class="row">
		<div class="col-md-2">
			<img class="author-pic" align="middle" src="/img/profile/philprofile.jpg" alt="Sorry, I'm looking beat today!">
		</div>
			<div class="col-md-1"></div>
			<div class="col-md-8">
				<span class="post-title">	<h2> Rise of the Machine Empire </h2> </span>
				<span class="post-date"><p><i>September 16th 2016</i></p></span>
				<span class="post-author"><p><i>Phillip Smith</i></p></span>
				<span class="post-content">

        <h3>Artificial Intelligence</h3>
         <p>I have spent some time listening to and considering the predictions for what is known as the singularity era of artificial intelligence. The singularity refers to a point in time when the intelligence of man is surpassed by that of machine. I believe that for such a thing to take place, the key factor would be if we can create learning and reasoning within machines that can process in the same capacity as it does the human brain. Now this is a very general statement so I will begin by putting a few of these terms in perspective. When I say machine, I am referring to the actual program code and processing unit that allow a machine to perform the functions it was designed; the brain of the machine. Giving a machine the ability to utilize human logic would be to, I believe, give the most possible ambiguity to the functions for which it was designed in that humans have an incalculable range of possible outputs for every input which makes it impossible to write simple IF/THEN code for neuron activity in the brain. This is where I agree with Turing that the only way to truly give a machine human-like intelligence is to give it the brain of a child, which he somewhat accurately describes as a blank notebook ready for experience to write code into so to speak.
         Let me elaborate on why I ìsomewhatî agree with Turingís analogy. The simple observation is that if a childís brain is like a blank notebook, a machineís brain is a blank notebook. Where the difference is lies in two qualities: the child can learn from inputs even when they are not intended to learn from them and the child has various motivations that cause it to behave a certain way even independent of inputs at times. In terms of the machine, this would mean that it would have to be able to write its own code on the fly from outer experience to meet the first requirement. Is that possible?</p>
         <p>The short answer is yes. Consider:</p>
         <ul>
           <li>We have the automated vacuum</li>
           <li>We almost have the self-driving car</li>
          <li>We have the Kinect</li>
         </ul>
         <p>The experiences that may happen to a child such as being spoken to, having obstacles block its path, and having to learn by watching others are basic sensory inputs that robotics engineers and computer programmers have spent years trying to recreate and they have (albeit in controlled situations mostly). For the scope of my examination, we can conclude from these examples that it is possible for a machine to be programmed to learn in a sense</p>

         <h3>The Illogical Reasoning Aspect:</h3>

          <p>I have seen my children do things they have been told not to almost instantly after being told. I have never tried to open Word and my computer opened PowerPoint instead (although with malware it is entirely possible). When dealing with the human brain, there is a logic to it and almost a sort of inherent illogical aspect as well at times. The illogical part is related to the many factors in the human that we would collectively call the conscience. Some light examples:</p>
         <ul>
           <li> if a human wears thick clothing when the weather is hot just because they feel that the clothing is appealing</li>
           <li> When a human breaks the law, such as speeding, in self-interest</li>
         </ul>
        <p>  These are examples of reasoning which machines are not yet capable: illogical reasoning; reasoning in which the answer that can be calculated as most beneficial or within the confines of the law is bypassed due to some personal, emotional input. A machine does not possess this type of factoring process; a machine will stay within defined parameters at all times unless it is broken in some way. </p>

        <p>Would it be possible to give a machine this ability to reason outside of defined parameters? </p>

        <p>That would require the machine be given humanlike components and emotions of some sort which would ultimately require a self-awareness.</p>


         <p>From what I have learned about artificial intelligence up to this point is that robots can simulate self-awareness to a degree but do not actually possess it:</p>
          <ul>
            <li>The vacuum does not really understand that it, as an entity, must avoid walls to do its job. It is simply programmed and equipped so that it can avoid walls. </li>
              <li>Some androids can carry on conversation interestingly well, but they do not hear themselves speak or have the delivery of someone that is ìspeaking from the heartî if you will.</li>
          </ul>
          <p>Even though machines can learn, they have no emotional reactivity to what they learn. For example, given an android that is like a child and programmed with far superior learning code than what exists today, in certain situations it will still behave far differently than a human child. </p>

        <h3>The Lizard Shop</h3>
         <p>A situation that still baffles me to this day is one I experienced in my teenage years at a reptile shop. The owners would give people a chance to stare at a baby snake in its glass cage until it attempted to strike. Now I knew for a fact that there was no possible scenario in this context, that I could imagine, where the snake could hurt me. Yet my response, all the same, was to jerk my face away as it struck. Given the parameters of the situation, the android would not move. The android would not move because it does not have the fear-based, illogical reasoning that I have. There are many instances, and explanations to match, for types of illogical reasoning that humans exhibit. This type of fear, from the scenario, is derived from survival instinct which, androids do not possess. Some others are doing activities, such as smoking, that humans know to be life threatening or choosing to procrastinate work to perform some other enjoyable activity. Machines do not have the ability to want, the concept of enjoyment, or, more importantly, the concept of death. Machines, as a result of not having the causes of illogical reasoning, are not capable of experiencing the mind states that they produce. Machines simply do what they are made to do, no matter how ambiguous those parameters are.</p>

        <p>As a side note, this means that if machines did decide to eradicate humans, we can take solace in the fact that it was the best calculated action as a result of human programmed parameters.</p>



        <h3>Final thoughts</h3>

         <p>Now, I will not go into detail about how we could create this illogical reasoning in them, but I believe it an interesting subject for another time, to examine the question of if we should or should not give them these traits. The last part of my discussion, after learning and reasoning, is capacity. The capacity of the strongest processor that is currently in regular usage is not near in the same realm as the calculations and activity that take place in the human brain. This is what makes the brain so difficult to understand and replicate in code. We simply do not know enough. In spite of that issue, though, I believe there is something in development that could surpass the calculating capacity of the brain, possibly changing everything we know about computing in general and definitely having strong effects on A.I. A new type of processor is being developed that uses quantum mechanics (of which I know very little). The basic theory is that, given an equation with variables, the quantum processor can solve by simultaneous performing all calculations. Some of these processors have been, albeit not widely, purchased and implemented for many purposes.

         That is not to say that singularity will be a reality any time soon, but what can be surmised is that machines surpassing humans in intelligence is within the realm of actual possibility. It is no longer just something portrayed in movies and sci-fi novels, but it is something that the scientific community as well as the general public may soon have to face.</p>


        <p>Now give me your thoughts on Artificial Intelligence below!</p>
      </span>
  </div>
  </div>

  <div disqus="5"></div>

  </div>
